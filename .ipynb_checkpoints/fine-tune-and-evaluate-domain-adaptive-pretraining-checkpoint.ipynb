{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWQHUy3sA2Ir"
   },
   "source": [
    "This script fine-tunes and evaluates DA-RoBERTa, DA-BERT, DA-BART, and DA-T5 on the BABE dataset by 5-fold cross-validation:\n",
    "\n",
    "Required data to run this script:\n",
    "- BABE.xlsx\n",
    "- the pretrained model that should be evaluated (selected model from https://drive.google.com/drive/folders/1-A1hGKeu-27X9I4ySkja5vMlVscnF8GR?usp=sharing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T13:49:47.391551Z",
     "iopub.status.busy": "2022-01-16T13:49:47.391177Z",
     "iopub.status.idle": "2022-01-16T13:50:12.887214Z",
     "shell.execute_reply": "2022-01-16T13:50:12.886381Z",
     "shell.execute_reply.started": "2022-01-16T13:49:47.391462Z"
    },
    "id": "2FbVfplXA-Nf",
    "outputId": "b45a868e-b678-47f5-94ff-3063b37893c7"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import io\n",
    "import sys\n",
    "import random\n",
    "import openpyxl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score,f1_score,precision_score,recall_score,accuracy_score,confusion_matrix\n",
    "import transformers\n",
    "from transformers import AdamW,BertTokenizer,BertModel,RobertaTokenizer,RobertaModel,T5EncoderModel,T5Tokenizer,BartModel,BartTokenizer\n",
    "from torch.utils.data import DataLoader,TensorDataset,RandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VWxBejP6T3E"
   },
   "source": [
    "**Create model architecture** (Uncomment respective model which should be evaluated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RoBERTa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-08T13:31:39.86612Z",
     "iopub.status.busy": "2022-01-08T13:31:39.865633Z",
     "iopub.status.idle": "2022-01-08T13:31:39.879666Z",
     "shell.execute_reply": "2022-01-08T13:31:39.879023Z",
     "shell.execute_reply.started": "2022-01-08T13:31:39.866083Z"
    },
    "id": "k5OstJYpMw5I"
   },
   "outputs": [],
   "source": [
    "# class RobertaClass(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(RobertaClass, self).__init__()\n",
    "#         self.roberta = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "#         self.vocab_transform = torch.nn.Linear(768, 768)\n",
    "#         self.dropout = torch.nn.Dropout(0.2)\n",
    "#         self.classifier1 = torch.nn.Linear(768,2)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         output_1 = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         hidden_state = output_1[0]\n",
    "#         pooler = hidden_state[:, 0]\n",
    "#         pooler = self.vocab_transform(pooler)\n",
    "#         pooler = self.dropout(pooler)\n",
    "#         output = self.classifier1(pooler)\n",
    "\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-08T13:42:01.076405Z",
     "iopub.status.busy": "2022-01-08T13:42:01.075779Z",
     "iopub.status.idle": "2022-01-08T13:42:01.083666Z",
     "shell.execute_reply": "2022-01-08T13:42:01.082799Z",
     "shell.execute_reply.started": "2022-01-08T13:42:01.076367Z"
    }
   },
   "outputs": [],
   "source": [
    "# class BertClass(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(BertClass, self).__init__()\n",
    "#         self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "#         self.vocab_transform = torch.nn.Linear(768, 768)\n",
    "#         self.dropout = torch.nn.Dropout(0.2)\n",
    "#         self.classifier1 = torch.nn.Linear(768,2)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         output_1 = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         hidden_state = output_1[0]\n",
    "#         pooler = hidden_state[:, 0]\n",
    "#         pooler = self.vocab_transform(pooler)\n",
    "#         pooler = self.dropout(pooler)\n",
    "#         output = self.classifier1(pooler)\n",
    "\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**T5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T13:50:31.704177Z",
     "iopub.status.busy": "2022-01-16T13:50:31.703549Z",
     "iopub.status.idle": "2022-01-16T13:50:31.712003Z",
     "shell.execute_reply": "2022-01-16T13:50:31.711017Z",
     "shell.execute_reply.started": "2022-01-16T13:50:31.704118Z"
    }
   },
   "outputs": [],
   "source": [
    "#create model\n",
    "# class T5Class(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(T5Class, self).__init__()\n",
    "#         self.T5 = T5EncoderModel.from_pretrained(\"t5-base\")\n",
    "#         self.vocab_transform = torch.nn.Linear(768, 768)\n",
    "#         self.dropout = torch.nn.Dropout(0.2)\n",
    "#         self.classifier1 = nn.Linear(768,2)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         output_1 = self.T5(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         hidden_state = output_1[0]\n",
    "#         pooler = hidden_state[:, 0]\n",
    "#         pooler = self.vocab_transform(pooler)\n",
    "#         pooler = self.dropout(pooler)\n",
    "#         output = self.classifier1(pooler)\n",
    "\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BART**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-08T13:59:31.924316Z",
     "iopub.status.busy": "2022-01-08T13:59:31.92387Z",
     "iopub.status.idle": "2022-01-08T13:59:31.931859Z",
     "shell.execute_reply": "2022-01-08T13:59:31.930848Z",
     "shell.execute_reply.started": "2022-01-08T13:59:31.924281Z"
    }
   },
   "outputs": [],
   "source": [
    "# #create model\n",
    "# class BartClass(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(BartClass, self).__init__()\n",
    "#         self.bart = BartModel.from_pretrained(\"facebook/bart-base\")\n",
    "#         self.vocab_transform = torch.nn.Linear(768, 768)\n",
    "#         self.dropout = torch.nn.Dropout(0.2)\n",
    "#         self.classifier1 = nn.Linear(768,2)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         output_1 = self.bart(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         hidden_state = output_1[0]\n",
    "#         pooler = hidden_state[:, 0]\n",
    "#         pooler = self.vocab_transform(pooler)\n",
    "#         pooler = self.dropout(pooler)\n",
    "#         output = self.classifier1(pooler)\n",
    "\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNRsqqn26YOu"
   },
   "source": [
    "**Connect to GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T13:50:34.736954Z",
     "iopub.status.busy": "2022-01-16T13:50:34.736381Z",
     "iopub.status.idle": "2022-01-16T13:50:34.790225Z",
     "shell.execute_reply": "2022-01-16T13:50:34.789204Z",
     "shell.execute_reply.started": "2022-01-16T13:50:34.736913Z"
    },
    "id": "CVAo1cx4J7RT",
    "outputId": "8a700457-85c8-4ba2-e1f1-fb2e72b3f277"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dC7ABPwV6jH5"
   },
   "source": [
    "**Load pre-trained domain-adapted weights/parameters for the model:** You might have to adapt the path pointing to the domain-adapted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T13:51:00.784923Z",
     "iopub.status.busy": "2022-01-16T13:51:00.784267Z",
     "iopub.status.idle": "2022-01-16T13:51:11.557579Z",
     "shell.execute_reply": "2022-01-16T13:51:11.55684Z",
     "shell.execute_reply.started": "2022-01-16T13:51:00.784886Z"
    },
    "id": "C7YkR_bhyd6P"
   },
   "outputs": [],
   "source": [
    "#load weights of pretrained news model\n",
    "#weight_dict = torch.load('Roberta.bin')\n",
    "#weight_dict = torch.load('BERT.bin')\n",
    "#weight_dict = torch.load('T5.bin')\n",
    "#weight_dict = torch.load('BART.bin')\n",
    "\n",
    "#load saved classifier weights + classifier bias --> we use same parameters for the final classification of all models to achieve maximum comparability\n",
    "classifier_weights = torch.load('../input/domainadaptivepretrainingjcdl/classifier.weights.pt')\n",
    "classifier_bias = torch.load('../input/domainadaptivepretrainingjcdl/classifier.bias.pt')\n",
    "\n",
    "#insert weights and bias into weight dict\n",
    "weight_dict['classifier1.weight'] = classifier_weights\n",
    "weight_dict['classifier1.bias'] = classifier_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WktGY1UUmztM"
   },
   "source": [
    "**Load BABE Data:** You might have to adapt the path again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T13:51:40.708992Z",
     "iopub.status.busy": "2022-01-16T13:51:40.708695Z",
     "iopub.status.idle": "2022-01-16T13:51:41.747378Z",
     "shell.execute_reply": "2022-01-16T13:51:41.746663Z",
     "shell.execute_reply.started": "2022-01-16T13:51:40.708959Z"
    },
    "id": "Aq7SkwILbrO9",
    "outputId": "36c41f76-6aa1-4fb3-a9b5-f29875ad2194"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"BABE.xlsx\")\n",
    "df = df[df['label_bias']!= 'No agreement']\n",
    "df['Label_bias_0-1'] = df['label_bias'].map({'Biased':1,'Non-biased':0})\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqbHOVdl7aJh"
   },
   "source": [
    "**Define Cross-Validation,Tokenizer,Batch Size,Epochs,Loss, and Seeds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T14:16:47.626163Z",
     "iopub.status.busy": "2022-01-16T14:16:47.625891Z",
     "iopub.status.idle": "2022-01-16T14:16:50.905503Z",
     "shell.execute_reply": "2022-01-16T14:16:50.904624Z",
     "shell.execute_reply.started": "2022-01-16T14:16:47.626114Z"
    },
    "id": "NOkpsCuGuQK3",
    "outputId": "626c1b1c-54ef-4248-a80f-26c03c502456"
   },
   "outputs": [],
   "source": [
    "np.random.seed(2018)\n",
    "torch.manual_seed(2018)   \n",
    "random.seed(2018)    \n",
    "torch.cuda.manual_seed_all(2018)\n",
    "random.seed(2018)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = 3,shuffle = True,random_state=2)\n",
    "#tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "#tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 10 #we implement an early stopping criterion. Fine-tuning is actually not done for 10 epochs\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUoIFq7n7ekg"
   },
   "source": [
    "**Define functions for fine-tuning and validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T14:16:50.907443Z",
     "iopub.status.busy": "2022-01-16T14:16:50.907102Z",
     "iopub.status.idle": "2022-01-16T14:16:50.91461Z",
     "shell.execute_reply": "2022-01-16T14:16:50.913794Z",
     "shell.execute_reply.started": "2022-01-16T14:16:50.907399Z"
    },
    "id": "oA6Np8VLxbuF"
   },
   "outputs": [],
   "source": [
    "def train(model):\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        optim_dbert.zero_grad()\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        outputs = model(sent_id, attention_mask=mask)\n",
    "        loss = cross_entropy(outputs,labels)\n",
    "        total_loss = total_loss+loss.item()\n",
    "        loss.backward()\n",
    "        optim_dbert.step()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T14:16:50.916723Z",
     "iopub.status.busy": "2022-01-16T14:16:50.916209Z",
     "iopub.status.idle": "2022-01-16T14:16:50.929015Z",
     "shell.execute_reply": "2022-01-16T14:16:50.928196Z",
     "shell.execute_reply.started": "2022-01-16T14:16:50.916682Z"
    },
    "id": "7VvtdBe3xj0h"
   },
   "outputs": [],
   "source": [
    "def validate(model):\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    print(\"\\n   Validating...\")\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(sent_id, attention_mask=mask)\n",
    "            loss = cross_entropy(outputs,labels)\n",
    "            total_loss = total_loss+loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(test_dataloader) \n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T14:16:53.319157Z",
     "iopub.status.busy": "2022-01-16T14:16:53.318866Z",
     "iopub.status.idle": "2022-01-16T14:16:53.331182Z",
     "shell.execute_reply": "2022-01-16T14:16:53.330167Z",
     "shell.execute_reply.started": "2022-01-16T14:16:53.319104Z"
    },
    "id": "krCHuXqsxn5l"
   },
   "outputs": [],
   "source": [
    "#combine train and validate function: get train and validation loss for every cross-validation split, save best-performing model, and get predictions on the held-out test set to calculate evaluation metrics\n",
    "\n",
    "def train_validate_pred(model):\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    # empty lists to store training and validation loss of each epoch\n",
    "    train_losses=[]\n",
    "    valid_losses=[]\n",
    "\n",
    "    #for each epoch\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print('\\n   Epoch {} / {}'.format(epoch+1,epochs))\n",
    "\n",
    "        #train model\n",
    "        train_loss = train(model)\n",
    "\n",
    "        #evaluate model\n",
    "        valid_loss = validate(model)\n",
    "\n",
    "        #save the best model\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            global model_dbert\n",
    "            torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "\n",
    "\n",
    "        #if validation loss increases, stop training\n",
    "        elif valid_loss >= best_valid_loss:\n",
    "            print(\"\\n Validation loss not decreased, Model of previous epoch saved\")\n",
    "            break\n",
    "\n",
    "        print(f'\\n    Training Loss: {train_loss:.3f}')\n",
    "        print(f'    Validation Loss: {valid_loss:.3f}')\n",
    "  \n",
    "    #predict\n",
    "    path = 'saved_weights.pt'\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    with torch.no_grad():\n",
    "        preds = model(test_seq.to(device), test_mask.to(device))\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "    preds = np.argmax(preds, axis = 1)\n",
    "  \n",
    "    #save results\n",
    "    loss.append(best_valid_loss)\n",
    "    acc.append(accuracy_score(test_y,preds))\n",
    "    auc.append(roc_auc_score(test_y,preds))\n",
    "    micro_F1.append(f1_score(test_y,preds,average='micro'))\n",
    "    macro_F1_weighted.append(f1_score(test_y,preds,average='weighted'))\n",
    "    binary_F1.append(f1_score(test_y,preds,average='binary'))\n",
    "    precision.append(precision_score(test_y,preds))\n",
    "    recall.append(recall_score(test_y,preds))\n",
    "    conf_matrix = confusion_matrix(test_y, preds)\n",
    "    conf_matrices.append(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T14:25:23.048044Z",
     "iopub.status.busy": "2022-01-16T14:25:23.047768Z",
     "iopub.status.idle": "2022-01-16T14:28:38.242361Z",
     "shell.execute_reply": "2022-01-16T14:28:38.241642Z",
     "shell.execute_reply.started": "2022-01-16T14:25:23.048015Z"
    },
    "id": "GhKHZ2S7Vxhx",
    "outputId": "0d3218ce-c57f-437c-99c9-2b214e219f00"
   },
   "outputs": [],
   "source": [
    "#implement cross validation + train/validate/predict\n",
    "loss = []\n",
    "acc = []\n",
    "auc = []\n",
    "micro_F1 = []\n",
    "macro_F1_weighted = []\n",
    "binary_F1 = []\n",
    "precision = []\n",
    "recall = []\n",
    "conf_matrices = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(df['text'], df['Label_bias_0-1'])):\n",
    "    sys.stdout.write('\\n \\r Fold {} / {}\\n'.format(fold+1,kfold.get_n_splits()))\n",
    "\n",
    "    #divide data into folds\n",
    "    train_text = df['text'].iloc[train_index]\n",
    "    test_text = df['text'].iloc[test_index]\n",
    "    train_labels = df['Label_bias_0-1'].iloc[train_index]\n",
    "    test_labels = df['Label_bias_0-1'].iloc[test_index]\n",
    "\n",
    "    #encode\n",
    "    train_encodings = tokenizer(train_text.tolist(), truncation=True, padding=True)\n",
    "    test_encodings = tokenizer(test_text.tolist(), truncation=True, padding=True)\n",
    "\n",
    "    #convert input to tensors \n",
    "    train_seq = torch.tensor(train_encodings['input_ids'])\n",
    "    train_mask = torch.tensor(train_encodings['attention_mask'])\n",
    "    train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "    test_seq = torch.tensor(test_encodings['input_ids'])\n",
    "    test_mask = torch.tensor(test_encodings['attention_mask'])\n",
    "    test_y = torch.tensor(test_labels.tolist())\n",
    "\n",
    "    # wrap tensors into one dataset\n",
    "    train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "    test_data = TensorDataset(test_seq, test_mask, test_y)\n",
    "\n",
    "    #define dataloader\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    test_sampler = RandomSampler(test_data)\n",
    "    train_dataloader = DataLoader(train_data,sampler= train_sampler, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data,sampler = test_sampler, batch_size=batch_size)\n",
    "\n",
    "    #create model instance with pre-trained weights and optimizer: insert respective model that is to be fine-tuned/evaluated\n",
    "#     model = BertClass()\n",
    "#     model = RobertaClass()\n",
    "#     model = BartClass()\n",
    "#     model = T5Class()\n",
    "    model.load_state_dict(weight_dict)\n",
    "    model.to(device)\n",
    "    optim_dbert = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "    #call train/validate/predict function\n",
    "    train_validate_pred(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T14:28:38.244066Z",
     "iopub.status.busy": "2022-01-16T14:28:38.243821Z",
     "iopub.status.idle": "2022-01-16T14:28:38.256684Z",
     "shell.execute_reply": "2022-01-16T14:28:38.254795Z",
     "shell.execute_reply.started": "2022-01-16T14:28:38.244032Z"
    },
    "id": "2oVjkc1rwW85"
   },
   "outputs": [],
   "source": [
    "#compute cross-validated performance metrics\n",
    "cv_loss = sum(loss)/len(loss)\n",
    "cv_acc = sum(acc)/len(acc)\n",
    "cv_auc = sum(auc)/len(auc)\n",
    "cv_micro_f1 = sum(micro_F1)/len(micro_F1)\n",
    "cv_macro_f1 = sum(macro_F1_weighted)/len(macro_F1_weighted)\n",
    "sd = np.std(macro_F1_weighted)\n",
    "cv_binary_f1 = sum(binary_F1)/len(binary_F1)\n",
    "cv_prec = sum(precision)/len(precision)\n",
    "cv_recall = sum(recall)/len(recall)\n",
    "cv_conf_matrix = np.mean(conf_matrices, axis=0)\n",
    "\n",
    "\n",
    "print(\"CV Accuracy = {}\".format(round(cv_acc,4)))\n",
    "print(\"CV AUC = {}\".format(round(cv_auc,4)))\n",
    "print(\"CV Micro F1 = {}\".format(round(cv_micro_f1,4)))\n",
    "print(\"CV Macro F1 weighted = {}\".format(round(cv_macro_f1,4)))\n",
    "print(\"SD = {}\".format(round(sd,4)))\n",
    "print(\"CV Binary F1 = {}\".format(round(cv_binary_f1,4)))\n",
    "print(\"CV Precision = {}\".format(round(cv_prec,4)))\n",
    "print(\"CV Recall = {}\".format(round(cv_recall,4)))\n",
    "print(\"CV Loss = {}\".format(round(cv_loss,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-08T09:47:10.408222Z",
     "iopub.status.busy": "2022-01-08T09:47:10.407751Z",
     "iopub.status.idle": "2022-01-08T09:47:10.416086Z",
     "shell.execute_reply": "2022-01-08T09:47:10.415289Z",
     "shell.execute_reply.started": "2022-01-08T09:47:10.408183Z"
    },
    "id": "ANOV_r5ZGWyV"
   },
   "outputs": [],
   "source": [
    "#optionally save metrics in dict\n",
    "#Roberta_DA_SG2_bs64_lr1e5_6ep = {\"loss\":cv_loss,\"micro_f1\":cv_micro_f1,\"macro_f1\":cv_macro_f1,\"SD\":sd,\"binary_f1\":cv_binary_f1,\"prec\":cv_prec,\"recall\":cv_recall}\n",
    "\n",
    "#store metrics in json format\n",
    "# with open('./Roberta_DA_SG2_bs64_lr1e5_6ep.json', 'w') as f:\n",
    "#     json.dump(Roberta_DA_SG2_bs64_lr1e5_6ep, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvJIY6pC-y0E"
   },
   "source": [
    "**McNemar test for statistical significance based on last cv split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T14:15:36.632564Z",
     "iopub.status.busy": "2022-01-16T14:15:36.632016Z",
     "iopub.status.idle": "2022-01-16T14:15:36.685915Z",
     "shell.execute_reply": "2022-01-16T14:15:36.685168Z",
     "shell.execute_reply.started": "2022-01-16T14:15:36.632525Z"
    },
    "id": "YzTY47jf-4Sb"
   },
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import mcnemar,mcnemar_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T14:29:03.823872Z",
     "iopub.status.busy": "2022-01-16T14:29:03.823608Z",
     "iopub.status.idle": "2022-01-16T14:29:08.188384Z",
     "shell.execute_reply": "2022-01-16T14:29:08.187624Z",
     "shell.execute_reply.started": "2022-01-16T14:29:03.823843Z"
    },
    "id": "DTTUBpXxASAc"
   },
   "outputs": [],
   "source": [
    "#get predictions for model on test set. Insert the domain-adapted model you want to evaluate here. Predictions are provided in the repository and do not have to be computed separately\n",
    "# with torch.no_grad():\n",
    "#     preds_DA = model(test_seq.to(device), test_mask.to(device))\n",
    "#     preds_DA = preds_DA.detach().cpu().numpy()\n",
    "# preds_DA = np.argmax(preds_DA, axis = 1)\n",
    "\n",
    "#optionally store predictions\n",
    "#np.save(\"preds_T5_DA.npy\",preds_T5_DA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T11:34:34.191214Z",
     "iopub.status.busy": "2022-01-14T11:34:34.190951Z",
     "iopub.status.idle": "2022-01-14T11:34:36.39085Z",
     "shell.execute_reply": "2022-01-14T11:34:36.390009Z",
     "shell.execute_reply.started": "2022-01-14T11:34:34.191185Z"
    }
   },
   "outputs": [],
   "source": [
    "# #get predictions for baseline model. Insert the baseline model you want to evaluate here.\n",
    "# with torch.no_grad():\n",
    "#     preds_noDA = model(test_seq.to(device), test_mask.to(device))\n",
    "#     preds_noDA = preds_noDA.detach().cpu().numpy()\n",
    "# preds_noDA = np.argmax(preds_noDA, axis = 1)\n",
    "\n",
    "#optionally store predictions\n",
    "# np.save(\"preds_T5_noDA.npy\",preds_T5_noDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T14:31:44.128687Z",
     "iopub.status.busy": "2022-01-16T14:31:44.127979Z",
     "iopub.status.idle": "2022-01-16T14:31:44.145542Z",
     "shell.execute_reply": "2022-01-16T14:31:44.144851Z",
     "shell.execute_reply.started": "2022-01-16T14:31:44.128648Z"
    },
    "id": "okzJKIcT-_Mh",
    "outputId": "03f2037a-630a-4ae2-a3bf-dd1be7fe8b6d"
   },
   "outputs": [],
   "source": [
    "# load predictions for baseline and domain-adapted model and get contingency table. Predictions are provided in the repository and do not have to be computed separately\n",
    "preds_noDA = np.load(\"preds_T5_noDA.npy\") #path might have to be adapted\n",
    "preds__DA = np.load(\"preds_T5_DA.npy\")\n",
    "tb = mcnemar_table(y_target=np.array(test_labels), \n",
    "                   y_model1=preds_roberta_noDA, \n",
    "                   y_model2=preds_roberta_DA)\n",
    "\n",
    "print(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T14:31:46.999499Z",
     "iopub.status.busy": "2022-01-16T14:31:46.998636Z",
     "iopub.status.idle": "2022-01-16T14:31:47.006977Z",
     "shell.execute_reply": "2022-01-16T14:31:47.006089Z",
     "shell.execute_reply.started": "2022-01-16T14:31:46.999447Z"
    },
    "id": "mSszecmS_gk-",
    "outputId": "1b78c5b7-1370-4be4-bc1f-e131398ff254"
   },
   "outputs": [],
   "source": [
    "#calculate McNemar test statistic\n",
    "chi2, p = mcnemar(ary=tb, corrected=True)\n",
    "print('chi-squared:', chi2)\n",
    "print('p-value:', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_s36EwTGkLJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
